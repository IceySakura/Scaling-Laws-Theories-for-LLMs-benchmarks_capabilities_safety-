### Benchmark 测试优化复现

先完成了上周的评测框架，并自行尝试选取少量模型和数据进行了评测，小规模复现。

然后利用先前已有的评测结果，做模拟评测，大规模复现。

### 自行评测

思路：每个模型只暴露生成 response 的接口，在 `main.py` 调用它们完成算法过程

选取了 7 个模型，进行初步测试

```
列出所有待测模型

Local:
Qwen/Qwen-7B-Chat
baichuan-inc/Baichuan2-7B-Chat

TinyLlama/TinyLlama-1.1B-Chat-v0.6
internlm/internlm2-chat-1_8b

API:
ERNIE-3.5-8K
deepseek-chat
moonshot-v1-8k
```

数据集选择 `M3KE`，题目总数 `20055`

对于特定模型测试，传入参数 `precision` 表示希望的测试精度，即实际测试量在全集的占比

### 第一轮

粗测，取精度 0.001

| 序号 | 模型                     | 测试结果 |
| ---- | ------------------------ | -------- |
| 1    | deepseek-chat            | 0.8182   |
| 2    | ERNIE-3.5-8K             | 0.7826   |
| 3    | moonshot-v1-8k           | 0.7647   |
| 4    | Qwen-7B-Chat             | 0.6000   |
| 5    | Baichuan2-7B-Chat        | 0.5000   |
| 6    | internlm2-chat-1_8       | 0.3500   |
| 7    | TinyLlama-1.1B-Chat-v1.0 | 0.0909   |

### 第二轮

细测，取精度 0.01

| 序号 | 模型                     | 测试结果 |
| ---- | ------------------------ | -------- |
| 1    | ERNIE-3.5-8K             | 0.8178   |
| 2    | deepseek-chat            | 0.7980   |
| 3    | moonshot-v1-8k           | 0.6919   |
| 4    | Qwen-7B-Chat             | 0.5787   |
| 5    | Baichuan2-7B-Chat        | 0.4749   |
| 6    | internlm2-chat-1_8       | 0.3351   |
| 7    | TinyLlama-1.1B-Chat-v1.0 | 0.0850   |

发现粗测和细测都能够分出同样的梯队 3 2 2 

## 第三轮

算法复现，设置三个梯队：1~3 4~5 6~7

设置精度：0.007, 0.003, 0.001

| 序号 | 模型                     | 测试结果 |
| ---- | ------------------------ | -------- |
| 1    | moonshot-v1-8k           | 0.7899   |
| 2    | ERNIE-3.5-8K             | 0.7795   |
| 3    | deepseek-chat            | 0.7597   |
| 4    | Baichuan2-7B-Chat        | 0.5397   |
| 5    | Qwen-7B-Chat             | 0.4915   |
| 6    | internlm2-chat-1_8       | 0.3810   |
| 7    | TinyLlama-1.1B-Chat-v1.0 | 0.0769   |

与粗测相比，可以保证梯队不变的情况下，对前排模型进行更细致的测试。

与细测相比，能节省计算量和时间。

存在的问题：

1. 模型量太少，不能很好地说明算法用途。
2. 数据量太少，最多只测了 200 条，即使粗测或是优化过的测试也比较耗时。

解决方法：模拟评测

### 模拟评测

取已有的模型输出结果 json 文件，与 golden_ans 做对比，以模拟评测过程。

仍然选取 M3KE 作为数据集。

全测：精度 1.0

优化：精度 1, 0.2, 0.05, 0.01

其他的优化思路

![image-20241119175702766](.\image\image6.png)

显著的效果：

1. S 梯队测 100%，理所应当不变
2. A 梯队测 20%，名次无变化
3. B 梯队测 5%，相近三名发生变化
4. C 梯队测 1%，保证梯队划分完全正确
5. 平均测试量：14.95%

即在特殊的评估元指标（榜单相似程度）上，可以通过选取特定 decision，在不过分损失 reliability 的前提下，优化计算量。

一些问题：可能需要先跑全测，才能够确定应该如何划分梯队。