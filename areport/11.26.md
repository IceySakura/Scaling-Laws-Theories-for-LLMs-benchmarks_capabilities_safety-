### **tinyBenchmarks: evaluating LLMs with fewer examples**

如何在 scenario 中采样，使得 examples 能够代表整个 scenario。
$$
\sum_{i \in \hat{I_j}}w_iY_{il} \approx \frac{1}{|I_j|}\sum_{i \in I_j} Y_{il}
$$
$l$ 待评测 llm

$I_j$ 第 j 个 scenario

$\hat{I_j}$ 采样后的第 j 个 scenario

$Y_{il} \in [0,1]$ 表示 l 在 i example 上的得分

#### 1. 分层随机采样

利用已有的 examples 分类情况。

对于有 subscenario 的情况，认为 subscenario 是对整个 scenario 情况的等分。

直接对每个 subscenario 等量随机采样，因此 $w_i = \frac{1}{|\hat{I_j}|}$。

#### 2. 聚类

改进取 $\hat{I_j}$ 的方式，不要随机采样。

得到的代表性 examples，称为锚点 "anchor points"，或者说所谓母题。

关键在于如何建立空间。

如何评价两个 example 是否相近？

##### 2.1. 基于正确性的聚类（Correctness-based Clustering）
motivation：一个模型在锚点 example 上正确 $\iff$ 它在该簇下其他 example 上是正确的。

考虑已有一个模型集合 $L_{tr}$ 完成了全部测试。

用不同模型给出的正确性得分，作为一个 example 的不同维度。

然后跑 k-means 聚类，找到每个聚类中心最近的 example 作为锚点（anchor points）

锚点组成 $\hat{I_j}$，每个锚点的权重 $w_i$ 是该锚点所在聚类中的例子数占总例子数的比例。

##### 2.2. 基于项目反应理论（IRT）的聚类（IRT-based Clustering）
motivation：心理测量学/教育学领域，IRT 模型，现代考试模型

假设每个 example 的答对概率取决于模型的潜在能力（$\theta$）和 example 的特性（$\alpha$ 和 $\beta$）。
$ p_{il} = P(Y_{il} = 1 | \theta_l, \alpha_i, \beta_i) = \frac{1}{1 + \exp(-\alpha_i^\top \theta_l + \beta_i)} $

$\theta_l \in R^d$ 模型 l 的能力向量

$\alpha_i \in R^d$ 问题 i 对不同能力的考察程度

$\beta_i \in R$ 问题 i 的难度，bias

考虑求出这些参数，然后取 $[\alpha_i,\beta_i]$ 作为每个 example 在空间中的点/向量。

使用变分推理的方法，

梯度下降方法优化变分分布的参数，使证据下界（Evidence Lower Bound, ELBO）最大化。

### 3. （先前）一些思考

不依赖已有模型测试结果，基于 example 本身的属性建立空间  $\alpha_i$？

达到问题分类，甚至量化 $\alpha_i$ 的效果。

一些人类习题中，可能会有出题人主观给出的考察能力，难度评定等。

缺点：有主观性，难以**详细**列举能力范围，**精确**量化指标。

似乎更适合做 subscenario 的划分。

